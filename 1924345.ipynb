{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* 请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.下载paddleX、跑通一个图像分类的示例\n",
    "### 1.1下载paddle X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.2跑通image classification示例\n",
    "本次试用的示例为**果蔬分类**\n",
    "\n",
    "<center><img src='https://ai-studio-static-online.cdn.bcebos.com/ac42cb4860b44496ad05ce3d3b37d661c4224843b756487dbb0a755373c468cd' width='700'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.分割任务实现\n",
    "\n",
    "### 2.1数据集下载和解压\n",
    "* 安装paddlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting paddlex\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/6d/4b/9cf2c1647ad6c3ec4104eabb7e58d8b588d254a15246371349a7d0df73b1/paddlex-1.3.9-py3-none-any.whl (516 kB)\n",
      "\u001b[K     |████████████████████████████████| 516 kB 12.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting shapely>=1.7.0\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/98/f8/db4d3426a1aba9d5dfcc83ed5a3e2935d2b1deb73d350642931791a61c37/Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 15.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (4.36.1)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (4.1.1.26)\n",
      "Collecting paddlehub==2.1.0\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/7a/29/3bd0ca43c787181e9c22fe44b944b64d7fcb14ce66d3bf4602d9ad2ac76c/paddlehub-2.1.0-py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 18.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: visualdl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (2.1.1)\n",
      "Collecting xlwt\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/44/48/def306413b25c3d01753603b1a222a011b8621aed27cd7f89cbc27e6b0f4/xlwt-1.3.0-py2.py3-none-any.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 12.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycocotools\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/de/df/056875d697c45182ed6d2ae21f62015896fdb841906fe48e7268e791c467/pycocotools-2.0.2.tar.gz (23 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (5.1.2)\n",
      "Collecting paddleslim==1.1.1\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/d1/77/e257227bed9a70ff0d35a4a3c4e70ac2d2362c803834c4c52018f7c4b762/paddleslim-1.1.1-py2.py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 31.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (0.4.4)\n",
      "Requirement already satisfied: sklearn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (0.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (5.7.2)\n",
      "Requirement already satisfied: flask-cors in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (3.0.8)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (18.1.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (7.1.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (1.16.4)\n",
      "Requirement already satisfied: rarfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (3.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (20.9)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (2.2.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (3.0.12)\n",
      "Collecting paddle2onnx>=0.5.1\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/3b/77/7111bee0ebafcb940cf9749b3ebf3b2b2113ac44326918f45a2b872a1586/paddle2onnx-0.5.1-py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 3.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: paddlenlp>=2.0.0rc5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (2.0.0rc7)\n",
      "Requirement already satisfied: flask>=1.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (1.1.1)\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (4.1.0)\n",
      "Requirement already satisfied: easydict in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (1.9)\n",
      "Requirement already satisfied: gunicorn>=19.10.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (20.0.4)\n",
      "Requirement already satisfied: gitpython in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex) (3.1.14)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==2.1.0->paddlex) (0.16.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==2.1.0->paddlex) (1.1.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==2.1.0->paddlex) (2.10.3)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==2.1.0->paddlex) (7.0)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gunicorn>=19.10.0->paddlehub==2.1.0->paddlex) (41.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.0->paddlehub==2.1.0->paddlex) (1.1.1)\n",
      "Requirement already satisfied: protobuf in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddle2onnx>=0.5.1->paddlehub==2.1.0->paddlex) (3.14.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddle2onnx>=0.5.1->paddlehub==2.1.0->paddlex) (1.15.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex) (2.9.0)\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex) (1.2.2)\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex) (0.42.1)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (0.7.1.1)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (1.21.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (2.22.0)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (3.8.2)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (0.8.53)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (1.0.0)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex) (2.2.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex) (0.6.1)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex) (2.6.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex) (0.23)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddlex) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddlex) (2019.3)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddlex) (3.9.9)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddlex) (0.18.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gitpython->paddlehub==2.1.0->paddlex) (4.0.5)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython->paddlehub==2.1.0->paddlex) (3.0.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->flake8>=3.7.9->visualdl>=2.0.0->paddlex) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata->flake8>=3.7.9->visualdl>=2.0.0->paddlex) (7.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddlehub==2.1.0->paddlex) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddlehub==2.1.0->paddlex) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddlehub==2.1.0->paddlex) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddlehub==2.1.0->paddlex) (0.10.0)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex) (1.3.4)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex) (16.7.9)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex) (1.3.0)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex) (0.10.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex) (2.0.1)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex) (1.4.10)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pycocotools->paddlex) (0.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex) (2019.9.11)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex) (1.3.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=278376 sha256=0d7d9e8c215a1bb49aff24c6dbdb80895f1bfcd26fc24de8de69dfb39ab13d11\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/3b/1c/8f/488903e8b13ce4f1f6397a0da41ea9df58356d7a7b56c89e38\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: paddle2onnx, xlwt, shapely, pycocotools, paddleslim, paddlehub, paddlex\n",
      "  Attempting uninstall: paddlehub\n",
      "    Found existing installation: paddlehub 2.0.4\n",
      "    Uninstalling paddlehub-2.0.4:\n",
      "      Successfully uninstalled paddlehub-2.0.4\n",
      "Successfully installed paddle2onnx-0.5.1 paddlehub-2.1.0 paddleslim-1.1.1 paddlex-1.3.9 pycocotools-2.0.2 shapely-1.7.1 xlwt-1.3.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install paddlex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* 下载和解压数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 09:48:46 [INFO]\tDownloading optic_disc_seg.tar.gz from https://bj.bcebos.com/paddlex/datasets/optic_disc_seg.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18631/18631 [00:00<00:00, 68924.22KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 09:48:47 [INFO]\tDecompressing ./optic_disc_seg.tar.gz...\n"
     ]
    }
   ],
   "source": [
    "import paddlex as pdx\n",
    "optic_dataset = 'https://bj.bcebos.com/paddlex/datasets/optic_disc_seg.tar.gz'\n",
    "pdx.utils.download_and_decompress(optic_dataset, path='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.2 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Dataset Split Done.\n",
      "Train samples: 267\n",
      "Eval samples: 76\n",
      "Test samples: 38\n",
      "Split files saved in optic_disc_seg\n"
     ]
    }
   ],
   "source": [
    "import paddlex\n",
    "!paddlex --split_dataset --format SEG --dataset_dir optic_disc_seg --val_value 0.2 --test_value 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3 语义分割模型训练及保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 09:48:49 [INFO]\t267 samples in file optic_disc_seg/train_list.txt\n",
      "2021-05-12 09:48:49 [INFO]\t76 samples in file optic_disc_seg/val_list.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/mobilenet_v3.py:231\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/segmentation/deeplabv3p.py:287\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/segmentation/deeplabv3p.py:315\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/segmentation/model_utils/loss.py:74\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "2021-05-12 09:48:50,113 - INFO - If regularizer of a Parameter has been set by 'fluid.ParamAttr' or 'fluid.WeightNormParamAttr' already. The Regularization[L2Decay, regularization_coeff=0.000040] in Optimizer will not take effect, and it will only be applied to other Parameters!\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 09:48:52 [INFO]\tConnecting PaddleHub server to get pretrain weights...\n",
      "Download https://paddle-imagenet-models-name.bj.bcebos.com/MobileNetV3_large_x1_0_ssld_pretrained.tar\n",
      "[##################################################] 100.00%\n",
      "Decompress /home/aistudio/.paddlehub/tmp/tmpik0ujkzl/MobileNetV3_large_x1_0_ssld_pretrained.tar\n",
      "[##################################################] 100.00%\n",
      "2021-05-12 09:48:53 [INFO]\tLoad pretrain weights from output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld.\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_expand_weights doesn't match.(Pretrained: (672, 112, 1, 1), Actual: (336, 112, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_expand_bn_scale doesn't match.(Pretrained: (672,), Actual: (336,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_expand_bn_offset doesn't match.(Pretrained: (672,), Actual: (336,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_expand_bn_mean doesn't match.(Pretrained: (672,), Actual: (336,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_expand_bn_variance doesn't match.(Pretrained: (672,), Actual: (336,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_depthwise_weights doesn't match.(Pretrained: (672, 1, 5, 5), Actual: (336, 1, 5, 5))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_depthwise_bn_scale doesn't match.(Pretrained: (672,), Actual: (336,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_depthwise_bn_offset doesn't match.(Pretrained: (672,), Actual: (336,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_depthwise_bn_mean doesn't match.(Pretrained: (672,), Actual: (336,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_depthwise_bn_variance doesn't match.(Pretrained: (672,), Actual: (336,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_se_1_weights doesn't match.(Pretrained: (168, 672, 1, 1), Actual: (84, 336, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_se_1_offset doesn't match.(Pretrained: (168,), Actual: (84,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_se_2_weights doesn't match.(Pretrained: (672, 168, 1, 1), Actual: (336, 84, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_se_2_offset doesn't match.(Pretrained: (672,), Actual: (336,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_linear_weights doesn't match.(Pretrained: (160, 672, 1, 1), Actual: (80, 336, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_linear_bn_scale doesn't match.(Pretrained: (160,), Actual: (80,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_linear_bn_offset doesn't match.(Pretrained: (160,), Actual: (80,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_linear_bn_mean doesn't match.(Pretrained: (160,), Actual: (80,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv14_linear_bn_variance doesn't match.(Pretrained: (160,), Actual: (80,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_expand_weights doesn't match.(Pretrained: (960, 160, 1, 1), Actual: (480, 80, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_expand_bn_scale doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_expand_bn_offset doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_expand_bn_mean doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_expand_bn_variance doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_depthwise_weights doesn't match.(Pretrained: (960, 1, 5, 5), Actual: (480, 1, 5, 5))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_depthwise_bn_scale doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_depthwise_bn_offset doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_depthwise_bn_mean doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_depthwise_bn_variance doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_se_1_weights doesn't match.(Pretrained: (240, 960, 1, 1), Actual: (120, 480, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_se_1_offset doesn't match.(Pretrained: (240,), Actual: (120,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_se_2_weights doesn't match.(Pretrained: (960, 240, 1, 1), Actual: (480, 120, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_se_2_offset doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_linear_weights doesn't match.(Pretrained: (160, 960, 1, 1), Actual: (80, 480, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_linear_bn_scale doesn't match.(Pretrained: (160,), Actual: (80,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_linear_bn_offset doesn't match.(Pretrained: (160,), Actual: (80,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_linear_bn_mean doesn't match.(Pretrained: (160,), Actual: (80,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv15_linear_bn_variance doesn't match.(Pretrained: (160,), Actual: (80,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_expand_weights doesn't match.(Pretrained: (960, 160, 1, 1), Actual: (480, 80, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_expand_bn_scale doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_expand_bn_offset doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_expand_bn_mean doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_expand_bn_variance doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_depthwise_weights doesn't match.(Pretrained: (960, 1, 5, 5), Actual: (480, 1, 5, 5))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_depthwise_bn_scale doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_depthwise_bn_offset doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_depthwise_bn_mean doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_depthwise_bn_variance doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_se_1_weights doesn't match.(Pretrained: (240, 960, 1, 1), Actual: (120, 480, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_se_1_offset doesn't match.(Pretrained: (240,), Actual: (120,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_se_2_weights doesn't match.(Pretrained: (960, 240, 1, 1), Actual: (480, 120, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_se_2_offset doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_linear_weights doesn't match.(Pretrained: (160, 960, 1, 1), Actual: (80, 480, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_linear_bn_scale doesn't match.(Pretrained: (160,), Actual: (80,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_linear_bn_offset doesn't match.(Pretrained: (160,), Actual: (80,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_linear_bn_mean doesn't match.(Pretrained: (160,), Actual: (80,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv16_linear_bn_variance doesn't match.(Pretrained: (160,), Actual: (80,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv_last_weights doesn't match.(Pretrained: (960, 160, 1, 1), Actual: (480, 80, 1, 1))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv_last_bn_scale doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv_last_bn_offset doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv_last_bn_mean doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [WARNING]\t[SKIP] Shape of pretrained weight output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld/conv_last_bn_variance doesn't match.(Pretrained: (960,), Actual: (480,))\n",
      "2021-05-12 09:48:53 [INFO]\tThere are 205 varaibles in output/deeplabv3p_mobilenetv3_large_ssld/pretrain/MobileNetV3_large_x1_0_ssld are loaded.\n",
      "2021-05-12 09:49:09 [INFO]\t[TRAIN] Epoch=1/10, Step=2/66, loss=0.417074, lr=0.009986, time_each_step=8.06s, eta=1:53:55\n",
      "2021-05-12 09:49:13 [INFO]\t[TRAIN] Epoch=1/10, Step=4/66, loss=0.121551, lr=0.009959, time_each_step=4.92s, eta=1:9:24\n",
      "2021-05-12 09:49:17 [INFO]\t[TRAIN] Epoch=1/10, Step=6/66, loss=0.135056, lr=0.009932, time_each_step=3.91s, eta=0:54:56\n",
      "2021-05-12 09:49:20 [INFO]\t[TRAIN] Epoch=1/10, Step=8/66, loss=0.20562, lr=0.009904, time_each_step=3.39s, eta=0:47:35\n",
      "2021-05-12 09:49:24 [INFO]\t[TRAIN] Epoch=1/10, Step=10/66, loss=0.164466, lr=0.009877, time_each_step=3.09s, eta=0:43:11\n",
      "2021-05-12 09:49:28 [INFO]\t[TRAIN] Epoch=1/10, Step=12/66, loss=0.158439, lr=0.00985, time_each_step=2.9s, eta=0:40:28\n",
      "2021-05-12 09:49:32 [INFO]\t[TRAIN] Epoch=1/10, Step=14/66, loss=0.163418, lr=0.009823, time_each_step=2.76s, eta=0:38:28\n",
      "2021-05-12 09:49:36 [INFO]\t[TRAIN] Epoch=1/10, Step=16/66, loss=0.208488, lr=0.009795, time_each_step=2.71s, eta=0:37:36\n",
      "2021-05-12 09:49:40 [INFO]\t[TRAIN] Epoch=1/10, Step=18/66, loss=0.120076, lr=0.009768, time_each_step=2.6s, eta=0:35:59\n",
      "2021-05-12 09:49:43 [INFO]\t[TRAIN] Epoch=1/10, Step=20/66, loss=0.087057, lr=0.009741, time_each_step=2.5s, eta=0:34:36\n",
      "2021-05-12 09:49:47 [INFO]\t[TRAIN] Epoch=1/10, Step=22/66, loss=0.05931, lr=0.009713, time_each_step=1.88s, eta=0:25:52\n",
      "2021-05-12 09:49:50 [INFO]\t[TRAIN] Epoch=1/10, Step=24/66, loss=0.051383, lr=0.009686, time_each_step=1.87s, eta=0:25:47\n",
      "2021-05-12 09:49:54 [INFO]\t[TRAIN] Epoch=1/10, Step=26/66, loss=0.04537, lr=0.009658, time_each_step=1.86s, eta=0:25:35\n",
      "2021-05-12 09:49:57 [INFO]\t[TRAIN] Epoch=1/10, Step=28/66, loss=0.032727, lr=0.009631, time_each_step=1.85s, eta=0:25:23\n",
      "2021-05-12 09:50:01 [INFO]\t[TRAIN] Epoch=1/10, Step=30/66, loss=0.073689, lr=0.009604, time_each_step=1.84s, eta=0:25:7\n",
      "2021-05-12 09:50:04 [INFO]\t[TRAIN] Epoch=1/10, Step=32/66, loss=0.076132, lr=0.009576, time_each_step=1.81s, eta=0:24:41\n",
      "2021-05-12 09:50:08 [INFO]\t[TRAIN] Epoch=1/10, Step=34/66, loss=0.034148, lr=0.009549, time_each_step=1.79s, eta=0:24:21\n",
      "2021-05-12 09:50:11 [INFO]\t[TRAIN] Epoch=1/10, Step=36/66, loss=0.043499, lr=0.009521, time_each_step=1.73s, eta=0:23:27\n",
      "2021-05-12 09:50:15 [INFO]\t[TRAIN] Epoch=1/10, Step=38/66, loss=0.057217, lr=0.009494, time_each_step=1.74s, eta=0:23:30\n",
      "2021-05-12 09:50:18 [INFO]\t[TRAIN] Epoch=1/10, Step=40/66, loss=0.014793, lr=0.009467, time_each_step=1.74s, eta=0:23:32\n",
      "2021-05-12 09:50:22 [INFO]\t[TRAIN] Epoch=1/10, Step=42/66, loss=0.035122, lr=0.009439, time_each_step=1.74s, eta=0:23:29\n",
      "2021-05-12 09:50:25 [INFO]\t[TRAIN] Epoch=1/10, Step=44/66, loss=0.058011, lr=0.009412, time_each_step=1.74s, eta=0:23:24\n",
      "2021-05-12 09:50:29 [INFO]\t[TRAIN] Epoch=1/10, Step=46/66, loss=0.048406, lr=0.009384, time_each_step=1.73s, eta=0:23:12\n",
      "2021-05-12 09:50:32 [INFO]\t[TRAIN] Epoch=1/10, Step=48/66, loss=0.020033, lr=0.009357, time_each_step=1.74s, eta=0:23:14\n",
      "2021-05-12 09:50:36 [INFO]\t[TRAIN] Epoch=1/10, Step=50/66, loss=0.029517, lr=0.009329, time_each_step=1.74s, eta=0:23:13\n",
      "2021-05-12 09:50:39 [INFO]\t[TRAIN] Epoch=1/10, Step=52/66, loss=0.024912, lr=0.009302, time_each_step=1.75s, eta=0:23:12\n",
      "2021-05-12 09:50:43 [INFO]\t[TRAIN] Epoch=1/10, Step=54/66, loss=0.03364, lr=0.009274, time_each_step=1.75s, eta=0:23:10\n",
      "2021-05-12 09:50:46 [INFO]\t[TRAIN] Epoch=1/10, Step=56/66, loss=0.031637, lr=0.009247, time_each_step=1.75s, eta=0:23:6\n",
      "2021-05-12 09:50:49 [INFO]\t[TRAIN] Epoch=1/10, Step=58/66, loss=0.025829, lr=0.009219, time_each_step=1.73s, eta=0:22:52\n",
      "2021-05-12 09:50:53 [INFO]\t[TRAIN] Epoch=1/10, Step=60/66, loss=0.017238, lr=0.009192, time_each_step=1.73s, eta=0:22:47\n",
      "2021-05-12 09:50:56 [INFO]\t[TRAIN] Epoch=1/10, Step=62/66, loss=0.02597, lr=0.009164, time_each_step=1.72s, eta=0:22:36\n",
      "2021-05-12 09:51:00 [INFO]\t[TRAIN] Epoch=1/10, Step=64/66, loss=0.03726, lr=0.009137, time_each_step=1.72s, eta=0:22:32\n",
      "2021-05-12 09:51:03 [INFO]\t[TRAIN] Epoch=1/10, Step=66/66, loss=0.025343, lr=0.009109, time_each_step=1.73s, eta=0:22:39\n",
      "2021-05-12 09:51:03 [INFO]\t[TRAIN] Epoch 1 finished, loss=0.081723, lr=0.009555 .\n",
      "2021-05-12 09:51:03 [INFO]\tStart to evaluating(total_samples=76, total_steps=19)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]share_vars_from is set, scope is ignored.\n",
      "100%|██████████| 19/19 [00:17<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 09:51:21 [INFO]\t[EVAL] Finished, Epoch=1, miou=0.688527, category_iou=[0.98898135 0.38807266], oacc=0.989058, category_acc=[0.98918949 0.97076879], kappa=0.55462, category_F1-score=[0.99446015 0.55915324] .\n",
      "2021-05-12 09:51:21 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/best_model.\n",
      "2021-05-12 09:51:21 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/epoch_1.\n",
      "2021-05-12 09:51:21 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_1, miou=0.6885270044086613\n",
      "2021-05-12 09:51:40 [INFO]\t[TRAIN] Epoch=2/10, Step=2/66, loss=0.024293, lr=0.009082, time_each_step=2.48s, eta=0:22:40\n",
      "2021-05-12 09:51:44 [INFO]\t[TRAIN] Epoch=2/10, Step=4/66, loss=0.044966, lr=0.009054, time_each_step=2.51s, eta=0:22:37\n",
      "2021-05-12 09:51:48 [INFO]\t[TRAIN] Epoch=2/10, Step=6/66, loss=0.016444, lr=0.009026, time_each_step=2.57s, eta=0:22:35\n",
      "2021-05-12 09:51:53 [INFO]\t[TRAIN] Epoch=2/10, Step=8/66, loss=0.0153, lr=0.008999, time_each_step=2.61s, eta=0:22:33\n",
      "2021-05-12 09:51:58 [INFO]\t[TRAIN] Epoch=2/10, Step=10/66, loss=0.028575, lr=0.008971, time_each_step=2.69s, eta=0:22:32\n",
      "2021-05-12 09:52:01 [INFO]\t[TRAIN] Epoch=2/10, Step=12/66, loss=0.015082, lr=0.008944, time_each_step=2.7s, eta=0:22:27\n",
      "2021-05-12 09:52:05 [INFO]\t[TRAIN] Epoch=2/10, Step=14/66, loss=0.027257, lr=0.008916, time_each_step=2.7s, eta=0:22:21\n",
      "2021-05-12 09:52:08 [INFO]\t[TRAIN] Epoch=2/10, Step=16/66, loss=0.046967, lr=0.008888, time_each_step=2.69s, eta=0:22:16\n",
      "2021-05-12 09:52:11 [INFO]\t[TRAIN] Epoch=2/10, Step=18/66, loss=0.016708, lr=0.008861, time_each_step=2.69s, eta=0:22:10\n",
      "2021-05-12 09:52:15 [INFO]\t[TRAIN] Epoch=2/10, Step=20/66, loss=0.022662, lr=0.008833, time_each_step=2.69s, eta=0:22:5\n",
      "2021-05-12 09:52:19 [INFO]\t[TRAIN] Epoch=2/10, Step=22/66, loss=0.024583, lr=0.008805, time_each_step=1.94s, eta=0:21:26\n",
      "2021-05-12 09:52:22 [INFO]\t[TRAIN] Epoch=2/10, Step=24/66, loss=0.019632, lr=0.008778, time_each_step=1.9s, eta=0:21:21\n",
      "2021-05-12 09:52:25 [INFO]\t[TRAIN] Epoch=2/10, Step=26/66, loss=0.017423, lr=0.00875, time_each_step=1.84s, eta=0:21:15\n",
      "2021-05-12 09:52:29 [INFO]\t[TRAIN] Epoch=2/10, Step=28/66, loss=0.026238, lr=0.008722, time_each_step=1.8s, eta=0:21:9\n",
      "2021-05-12 09:52:32 [INFO]\t[TRAIN] Epoch=2/10, Step=30/66, loss=0.019041, lr=0.008695, time_each_step=1.73s, eta=0:21:3\n",
      "2021-05-12 09:52:36 [INFO]\t[TRAIN] Epoch=2/10, Step=32/66, loss=0.02706, lr=0.008667, time_each_step=1.72s, eta=0:21:0\n",
      "2021-05-12 09:52:39 [INFO]\t[TRAIN] Epoch=2/10, Step=34/66, loss=0.030265, lr=0.008639, time_each_step=1.72s, eta=0:20:56\n",
      "2021-05-12 09:52:43 [INFO]\t[TRAIN] Epoch=2/10, Step=36/66, loss=0.018931, lr=0.008612, time_each_step=1.74s, eta=0:20:53\n",
      "2021-05-12 09:52:46 [INFO]\t[TRAIN] Epoch=2/10, Step=38/66, loss=0.014056, lr=0.008584, time_each_step=1.74s, eta=0:20:50\n",
      "2021-05-12 09:52:50 [INFO]\t[TRAIN] Epoch=2/10, Step=40/66, loss=0.012041, lr=0.008556, time_each_step=1.74s, eta=0:20:46\n",
      "2021-05-12 09:52:53 [INFO]\t[TRAIN] Epoch=2/10, Step=42/66, loss=0.0189, lr=0.008528, time_each_step=1.73s, eta=0:20:42\n",
      "2021-05-12 09:52:56 [INFO]\t[TRAIN] Epoch=2/10, Step=44/66, loss=0.024523, lr=0.008501, time_each_step=1.73s, eta=0:20:39\n",
      "2021-05-12 09:53:00 [INFO]\t[TRAIN] Epoch=2/10, Step=46/66, loss=0.014089, lr=0.008473, time_each_step=1.73s, eta=0:20:36\n",
      "2021-05-12 09:53:03 [INFO]\t[TRAIN] Epoch=2/10, Step=48/66, loss=0.014717, lr=0.008445, time_each_step=1.72s, eta=0:20:32\n",
      "2021-05-12 09:53:07 [INFO]\t[TRAIN] Epoch=2/10, Step=50/66, loss=0.018434, lr=0.008417, time_each_step=1.72s, eta=0:20:29\n",
      "2021-05-12 09:53:10 [INFO]\t[TRAIN] Epoch=2/10, Step=52/66, loss=0.014851, lr=0.008389, time_each_step=1.72s, eta=0:20:25\n",
      "2021-05-12 09:53:14 [INFO]\t[TRAIN] Epoch=2/10, Step=54/66, loss=0.015514, lr=0.008362, time_each_step=1.73s, eta=0:20:22\n",
      "2021-05-12 09:53:17 [INFO]\t[TRAIN] Epoch=2/10, Step=56/66, loss=0.024295, lr=0.008334, time_each_step=1.72s, eta=0:20:18\n",
      "2021-05-12 09:53:21 [INFO]\t[TRAIN] Epoch=2/10, Step=58/66, loss=0.013032, lr=0.008306, time_each_step=1.71s, eta=0:20:15\n",
      "2021-05-12 09:53:24 [INFO]\t[TRAIN] Epoch=2/10, Step=60/66, loss=0.013305, lr=0.008278, time_each_step=1.72s, eta=0:20:11\n",
      "2021-05-12 09:53:28 [INFO]\t[TRAIN] Epoch=2/10, Step=62/66, loss=0.016318, lr=0.00825, time_each_step=1.72s, eta=0:20:8\n",
      "2021-05-12 09:53:31 [INFO]\t[TRAIN] Epoch=2/10, Step=64/66, loss=0.02856, lr=0.008222, time_each_step=1.72s, eta=0:20:5\n",
      "2021-05-12 09:53:34 [INFO]\t[TRAIN] Epoch=2/10, Step=66/66, loss=0.02067, lr=0.008194, time_each_step=1.72s, eta=0:20:1\n",
      "2021-05-12 09:53:34 [INFO]\t[TRAIN] Epoch 2 finished, loss=0.022844, lr=0.008646 .\n",
      "2021-05-12 09:53:34 [INFO]\tStart to evaluating(total_samples=76, total_steps=19)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 09:53:51 [INFO]\t[EVAL] Finished, Epoch=2, miou=0.832741, category_iou=[0.99366054 0.67182153], oacc=0.993742, category_acc=[0.99506875 0.90167421], kappa=0.800558, category_F1-score=[0.99682019 0.80370006] .\n",
      "2021-05-12 09:53:52 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/best_model.\n",
      "2021-05-12 09:53:52 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/epoch_2.\n",
      "2021-05-12 09:53:52 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_2, miou=0.8327410395339463\n",
      "2021-05-12 09:54:08 [INFO]\t[TRAIN] Epoch=3/10, Step=2/66, loss=0.009141, lr=0.008167, time_each_step=2.35s, eta=0:20:24\n",
      "2021-05-12 09:54:12 [INFO]\t[TRAIN] Epoch=3/10, Step=4/66, loss=0.011631, lr=0.008139, time_each_step=2.4s, eta=0:20:22\n",
      "2021-05-12 09:54:17 [INFO]\t[TRAIN] Epoch=3/10, Step=6/66, loss=0.013082, lr=0.008111, time_each_step=2.44s, eta=0:20:20\n",
      "2021-05-12 09:54:21 [INFO]\t[TRAIN] Epoch=3/10, Step=8/66, loss=0.013584, lr=0.008083, time_each_step=2.49s, eta=0:20:18\n",
      "2021-05-12 09:54:26 [INFO]\t[TRAIN] Epoch=3/10, Step=10/66, loss=0.04071, lr=0.008055, time_each_step=2.53s, eta=0:20:16\n",
      "2021-05-12 09:54:29 [INFO]\t[TRAIN] Epoch=3/10, Step=12/66, loss=0.042221, lr=0.008027, time_each_step=2.54s, eta=0:20:11\n",
      "2021-05-12 09:54:33 [INFO]\t[TRAIN] Epoch=3/10, Step=14/66, loss=0.015489, lr=0.007999, time_each_step=2.54s, eta=0:20:6\n",
      "2021-05-12 09:54:36 [INFO]\t[TRAIN] Epoch=3/10, Step=16/66, loss=0.016194, lr=0.007971, time_each_step=2.54s, eta=0:20:1\n",
      "2021-05-12 09:54:40 [INFO]\t[TRAIN] Epoch=3/10, Step=18/66, loss=0.026202, lr=0.007943, time_each_step=2.54s, eta=0:19:56\n",
      "2021-05-12 09:54:43 [INFO]\t[TRAIN] Epoch=3/10, Step=20/66, loss=0.017516, lr=0.007915, time_each_step=2.54s, eta=0:19:51\n",
      "2021-05-12 09:54:46 [INFO]\t[TRAIN] Epoch=3/10, Step=22/66, loss=0.013764, lr=0.007887, time_each_step=1.91s, eta=0:19:18\n",
      "2021-05-12 09:54:50 [INFO]\t[TRAIN] Epoch=3/10, Step=24/66, loss=0.013985, lr=0.007859, time_each_step=1.88s, eta=0:19:13\n",
      "2021-05-12 09:54:53 [INFO]\t[TRAIN] Epoch=3/10, Step=26/66, loss=0.012375, lr=0.007831, time_each_step=1.85s, eta=0:19:8\n",
      "2021-05-12 09:54:57 [INFO]\t[TRAIN] Epoch=3/10, Step=28/66, loss=0.01231, lr=0.007803, time_each_step=1.79s, eta=0:19:2\n",
      "2021-05-12 09:55:00 [INFO]\t[TRAIN] Epoch=3/10, Step=30/66, loss=0.022958, lr=0.007775, time_each_step=1.73s, eta=0:18:56\n",
      "2021-05-12 09:55:04 [INFO]\t[TRAIN] Epoch=3/10, Step=32/66, loss=0.013785, lr=0.007747, time_each_step=1.72s, eta=0:18:52\n",
      "2021-05-12 09:55:07 [INFO]\t[TRAIN] Epoch=3/10, Step=34/66, loss=0.011306, lr=0.007719, time_each_step=1.72s, eta=0:18:49\n",
      "2021-05-12 09:55:10 [INFO]\t[TRAIN] Epoch=3/10, Step=36/66, loss=0.014762, lr=0.007691, time_each_step=1.72s, eta=0:18:45\n",
      "2021-05-12 09:55:14 [INFO]\t[TRAIN] Epoch=3/10, Step=38/66, loss=0.017681, lr=0.007663, time_each_step=1.71s, eta=0:18:42\n",
      "2021-05-12 09:55:17 [INFO]\t[TRAIN] Epoch=3/10, Step=40/66, loss=0.025147, lr=0.007635, time_each_step=1.72s, eta=0:18:38\n",
      "2021-05-12 09:55:21 [INFO]\t[TRAIN] Epoch=3/10, Step=42/66, loss=0.01741, lr=0.007607, time_each_step=1.72s, eta=0:18:35\n",
      "2021-05-12 09:55:24 [INFO]\t[TRAIN] Epoch=3/10, Step=44/66, loss=0.012502, lr=0.007578, time_each_step=1.7s, eta=0:18:31\n",
      "2021-05-12 09:55:28 [INFO]\t[TRAIN] Epoch=3/10, Step=46/66, loss=0.039264, lr=0.00755, time_each_step=1.71s, eta=0:18:28\n",
      "2021-05-12 09:55:31 [INFO]\t[TRAIN] Epoch=3/10, Step=48/66, loss=0.017261, lr=0.007522, time_each_step=1.71s, eta=0:18:25\n",
      "2021-05-12 09:55:34 [INFO]\t[TRAIN] Epoch=3/10, Step=50/66, loss=0.016157, lr=0.007494, time_each_step=1.71s, eta=0:18:21\n",
      "2021-05-12 09:55:38 [INFO]\t[TRAIN] Epoch=3/10, Step=52/66, loss=0.01254, lr=0.007466, time_each_step=1.72s, eta=0:18:18\n",
      "2021-05-12 09:55:41 [INFO]\t[TRAIN] Epoch=3/10, Step=54/66, loss=0.009406, lr=0.007438, time_each_step=1.71s, eta=0:18:14\n",
      "2021-05-12 09:55:45 [INFO]\t[TRAIN] Epoch=3/10, Step=56/66, loss=0.009965, lr=0.007409, time_each_step=1.71s, eta=0:18:11\n",
      "2021-05-12 09:55:48 [INFO]\t[TRAIN] Epoch=3/10, Step=58/66, loss=0.01033, lr=0.007381, time_each_step=1.7s, eta=0:18:7\n",
      "2021-05-12 09:55:51 [INFO]\t[TRAIN] Epoch=3/10, Step=60/66, loss=0.01651, lr=0.007353, time_each_step=1.7s, eta=0:18:4\n",
      "2021-05-12 09:55:55 [INFO]\t[TRAIN] Epoch=3/10, Step=62/66, loss=0.015235, lr=0.007325, time_each_step=1.71s, eta=0:18:1\n",
      "2021-05-12 09:55:58 [INFO]\t[TRAIN] Epoch=3/10, Step=64/66, loss=0.01777, lr=0.007297, time_each_step=1.71s, eta=0:17:57\n",
      "2021-05-12 09:56:02 [INFO]\t[TRAIN] Epoch=3/10, Step=66/66, loss=0.022713, lr=0.007268, time_each_step=1.7s, eta=0:17:54\n",
      "2021-05-12 09:56:02 [INFO]\t[TRAIN] Epoch 3 finished, loss=0.01799, lr=0.007725 .\n",
      "2021-05-12 09:56:02 [INFO]\tStart to evaluating(total_samples=76, total_steps=19)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:16<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 09:56:18 [INFO]\t[EVAL] Finished, Epoch=3, miou=0.84993, category_iou=[0.99420753 0.70565229], oacc=0.994287, category_acc=[0.99596146 0.8874557 ], kappa=0.824537, category_F1-score=[0.99709535 0.82742807] .\n",
      "2021-05-12 09:56:18 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/best_model.\n",
      "2021-05-12 09:56:18 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/epoch_3.\n",
      "2021-05-12 09:56:18 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_3, miou=0.8499299069457754\n",
      "2021-05-12 09:56:35 [INFO]\t[TRAIN] Epoch=4/10, Step=2/66, loss=0.014427, lr=0.00724, time_each_step=2.35s, eta=0:17:25\n",
      "2021-05-12 09:56:39 [INFO]\t[TRAIN] Epoch=4/10, Step=4/66, loss=0.025738, lr=0.007212, time_each_step=2.39s, eta=0:17:23\n",
      "2021-05-12 09:56:43 [INFO]\t[TRAIN] Epoch=4/10, Step=6/66, loss=0.019685, lr=0.007183, time_each_step=2.43s, eta=0:17:21\n",
      "2021-05-12 09:56:48 [INFO]\t[TRAIN] Epoch=4/10, Step=8/66, loss=0.014028, lr=0.007155, time_each_step=2.49s, eta=0:17:19\n",
      "2021-05-12 09:56:52 [INFO]\t[TRAIN] Epoch=4/10, Step=10/66, loss=0.014749, lr=0.007127, time_each_step=2.54s, eta=0:17:17\n",
      "2021-05-12 09:56:56 [INFO]\t[TRAIN] Epoch=4/10, Step=12/66, loss=0.011709, lr=0.007099, time_each_step=2.56s, eta=0:17:13\n",
      "2021-05-12 09:57:00 [INFO]\t[TRAIN] Epoch=4/10, Step=14/66, loss=0.010579, lr=0.00707, time_each_step=2.57s, eta=0:17:8\n",
      "2021-05-12 09:57:03 [INFO]\t[TRAIN] Epoch=4/10, Step=16/66, loss=0.013264, lr=0.007042, time_each_step=2.57s, eta=0:17:3\n",
      "2021-05-12 09:57:07 [INFO]\t[TRAIN] Epoch=4/10, Step=18/66, loss=0.019247, lr=0.007013, time_each_step=2.57s, eta=0:16:58\n",
      "2021-05-12 09:57:10 [INFO]\t[TRAIN] Epoch=4/10, Step=20/66, loss=0.012571, lr=0.006985, time_each_step=2.58s, eta=0:16:54\n",
      "2021-05-12 09:57:13 [INFO]\t[TRAIN] Epoch=4/10, Step=22/66, loss=0.019343, lr=0.006957, time_each_step=1.93s, eta=0:16:20\n",
      "2021-05-12 09:57:17 [INFO]\t[TRAIN] Epoch=4/10, Step=24/66, loss=0.010389, lr=0.006928, time_each_step=1.89s, eta=0:16:14\n",
      "2021-05-12 09:57:20 [INFO]\t[TRAIN] Epoch=4/10, Step=26/66, loss=0.01768, lr=0.0069, time_each_step=1.85s, eta=0:16:9\n",
      "2021-05-12 09:57:24 [INFO]\t[TRAIN] Epoch=4/10, Step=28/66, loss=0.010594, lr=0.006871, time_each_step=1.79s, eta=0:16:3\n",
      "2021-05-12 09:57:27 [INFO]\t[TRAIN] Epoch=4/10, Step=30/66, loss=0.017241, lr=0.006843, time_each_step=1.75s, eta=0:15:58\n",
      "2021-05-12 09:57:30 [INFO]\t[TRAIN] Epoch=4/10, Step=32/66, loss=0.01161, lr=0.006815, time_each_step=1.72s, eta=0:15:53\n",
      "2021-05-12 09:57:34 [INFO]\t[TRAIN] Epoch=4/10, Step=34/66, loss=0.019024, lr=0.006786, time_each_step=1.71s, eta=0:15:50\n",
      "2021-05-12 09:57:37 [INFO]\t[TRAIN] Epoch=4/10, Step=36/66, loss=0.011367, lr=0.006758, time_each_step=1.71s, eta=0:15:46\n",
      "2021-05-12 09:57:41 [INFO]\t[TRAIN] Epoch=4/10, Step=38/66, loss=0.010936, lr=0.006729, time_each_step=1.72s, eta=0:15:43\n",
      "2021-05-12 09:57:44 [INFO]\t[TRAIN] Epoch=4/10, Step=40/66, loss=0.014343, lr=0.006701, time_each_step=1.71s, eta=0:15:39\n",
      "2021-05-12 09:57:48 [INFO]\t[TRAIN] Epoch=4/10, Step=42/66, loss=0.015579, lr=0.006672, time_each_step=1.71s, eta=0:15:36\n",
      "2021-05-12 09:57:51 [INFO]\t[TRAIN] Epoch=4/10, Step=44/66, loss=0.01915, lr=0.006644, time_each_step=1.71s, eta=0:15:32\n",
      "2021-05-12 09:57:54 [INFO]\t[TRAIN] Epoch=4/10, Step=46/66, loss=0.01931, lr=0.006615, time_each_step=1.7s, eta=0:15:29\n",
      "2021-05-12 09:57:58 [INFO]\t[TRAIN] Epoch=4/10, Step=48/66, loss=0.030664, lr=0.006586, time_each_step=1.71s, eta=0:15:26\n",
      "2021-05-12 09:58:02 [INFO]\t[TRAIN] Epoch=4/10, Step=50/66, loss=0.021431, lr=0.006558, time_each_step=1.73s, eta=0:15:22\n",
      "2021-05-12 09:58:05 [INFO]\t[TRAIN] Epoch=4/10, Step=52/66, loss=0.016365, lr=0.006529, time_each_step=1.73s, eta=0:15:19\n",
      "2021-05-12 09:58:09 [INFO]\t[TRAIN] Epoch=4/10, Step=54/66, loss=0.013307, lr=0.006501, time_each_step=1.74s, eta=0:15:16\n",
      "2021-05-12 09:58:12 [INFO]\t[TRAIN] Epoch=4/10, Step=56/66, loss=0.013917, lr=0.006472, time_each_step=1.73s, eta=0:15:12\n",
      "2021-05-12 09:58:15 [INFO]\t[TRAIN] Epoch=4/10, Step=58/66, loss=0.01338, lr=0.006443, time_each_step=1.73s, eta=0:15:9\n",
      "2021-05-12 09:58:19 [INFO]\t[TRAIN] Epoch=4/10, Step=60/66, loss=0.0137, lr=0.006415, time_each_step=1.74s, eta=0:15:5\n",
      "2021-05-12 09:58:22 [INFO]\t[TRAIN] Epoch=4/10, Step=62/66, loss=0.015837, lr=0.006386, time_each_step=1.74s, eta=0:15:2\n",
      "2021-05-12 09:58:26 [INFO]\t[TRAIN] Epoch=4/10, Step=64/66, loss=0.016081, lr=0.006357, time_each_step=1.74s, eta=0:14:58\n",
      "2021-05-12 09:58:29 [INFO]\t[TRAIN] Epoch=4/10, Step=66/66, loss=0.035357, lr=0.006329, time_each_step=1.74s, eta=0:14:55\n",
      "2021-05-12 09:58:29 [INFO]\t[TRAIN] Epoch 4 finished, loss=0.017585, lr=0.006793 .\n",
      "2021-05-12 09:58:29 [INFO]\tStart to evaluating(total_samples=76, total_steps=19)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:16<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 09:58:46 [INFO]\t[EVAL] Finished, Epoch=4, miou=0.862621, category_iou=[0.99442234 0.73081984], oacc=0.994506, category_acc=[0.99719528 0.84485937], kappa=0.841682, category_F1-score=[0.99720337 0.84447823] .\n",
      "2021-05-12 09:58:47 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/best_model.\n",
      "2021-05-12 09:58:47 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/epoch_4.\n",
      "2021-05-12 09:58:47 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_4, miou=0.8626210870662588\n",
      "2021-05-12 09:59:04 [INFO]\t[TRAIN] Epoch=5/10, Step=2/66, loss=0.012297, lr=0.0063, time_each_step=2.42s, eta=0:15:14\n",
      "2021-05-12 09:59:08 [INFO]\t[TRAIN] Epoch=5/10, Step=4/66, loss=0.021956, lr=0.006271, time_each_step=2.45s, eta=0:15:11\n",
      "2021-05-12 09:59:26 [INFO]\t[TRAIN] Epoch=5/10, Step=12/66, loss=0.014268, lr=0.006156, time_each_step=2.64s, eta=0:15:1\n",
      "2021-05-12 09:59:29 [INFO]\t[TRAIN] Epoch=5/10, Step=14/66, loss=0.006983, lr=0.006128, time_each_step=2.64s, eta=0:14:56\n",
      "2021-05-12 09:59:33 [INFO]\t[TRAIN] Epoch=5/10, Step=16/66, loss=0.018069, lr=0.006099, time_each_step=2.64s, eta=0:14:51\n",
      "2021-05-12 09:59:36 [INFO]\t[TRAIN] Epoch=5/10, Step=18/66, loss=0.010607, lr=0.00607, time_each_step=2.64s, eta=0:14:45\n",
      "2021-05-12 09:59:50 [INFO]\t[TRAIN] Epoch=5/10, Step=26/66, loss=0.015295, lr=0.005955, time_each_step=1.86s, eta=0:13:53\n",
      "2021-05-12 09:59:54 [INFO]\t[TRAIN] Epoch=5/10, Step=28/66, loss=0.011828, lr=0.005926, time_each_step=1.81s, eta=0:13:48\n",
      "2021-05-12 09:59:57 [INFO]\t[TRAIN] Epoch=5/10, Step=30/66, loss=0.014921, lr=0.005897, time_each_step=1.73s, eta=0:13:41\n",
      "2021-05-12 10:00:00 [INFO]\t[TRAIN] Epoch=5/10, Step=32/66, loss=0.008502, lr=0.005868, time_each_step=1.73s, eta=0:13:38\n",
      "2021-05-12 10:00:04 [INFO]\t[TRAIN] Epoch=5/10, Step=34/66, loss=0.021679, lr=0.005839, time_each_step=1.73s, eta=0:13:34\n",
      "2021-05-12 10:00:07 [INFO]\t[TRAIN] Epoch=5/10, Step=36/66, loss=0.010581, lr=0.00581, time_each_step=1.73s, eta=0:13:31\n",
      "2021-05-12 10:00:11 [INFO]\t[TRAIN] Epoch=5/10, Step=38/66, loss=0.010823, lr=0.005781, time_each_step=1.75s, eta=0:13:28\n",
      "2021-05-12 10:00:15 [INFO]\t[TRAIN] Epoch=5/10, Step=40/66, loss=0.029009, lr=0.005752, time_each_step=1.74s, eta=0:13:24\n",
      "2021-05-12 10:00:18 [INFO]\t[TRAIN] Epoch=5/10, Step=42/66, loss=0.011998, lr=0.005723, time_each_step=1.74s, eta=0:13:21\n",
      "2021-05-12 10:00:21 [INFO]\t[TRAIN] Epoch=5/10, Step=44/66, loss=0.008594, lr=0.005694, time_each_step=1.74s, eta=0:13:17\n",
      "2021-05-12 10:00:25 [INFO]\t[TRAIN] Epoch=5/10, Step=46/66, loss=0.029905, lr=0.005665, time_each_step=1.73s, eta=0:13:14\n",
      "2021-05-12 10:00:28 [INFO]\t[TRAIN] Epoch=5/10, Step=48/66, loss=0.013314, lr=0.005636, time_each_step=1.72s, eta=0:13:10\n",
      "2021-05-12 10:00:31 [INFO]\t[TRAIN] Epoch=5/10, Step=50/66, loss=0.010137, lr=0.005607, time_each_step=1.72s, eta=0:13:6\n",
      "2021-05-12 10:00:35 [INFO]\t[TRAIN] Epoch=5/10, Step=52/66, loss=0.010086, lr=0.005578, time_each_step=1.72s, eta=0:13:3\n",
      "2021-05-12 10:00:38 [INFO]\t[TRAIN] Epoch=5/10, Step=54/66, loss=0.015336, lr=0.005548, time_each_step=1.71s, eta=0:12:59\n",
      "2021-05-12 10:00:42 [INFO]\t[TRAIN] Epoch=5/10, Step=56/66, loss=0.02562, lr=0.005519, time_each_step=1.71s, eta=0:12:56\n",
      "2021-05-12 10:00:45 [INFO]\t[TRAIN] Epoch=5/10, Step=58/66, loss=0.032432, lr=0.00549, time_each_step=1.69s, eta=0:12:52\n",
      "2021-05-12 10:00:48 [INFO]\t[TRAIN] Epoch=5/10, Step=60/66, loss=0.023932, lr=0.005461, time_each_step=1.7s, eta=0:12:49\n",
      "2021-05-12 10:00:52 [INFO]\t[TRAIN] Epoch=5/10, Step=62/66, loss=0.008089, lr=0.005432, time_each_step=1.69s, eta=0:12:46\n",
      "2021-05-12 10:00:55 [INFO]\t[TRAIN] Epoch=5/10, Step=64/66, loss=0.01808, lr=0.005403, time_each_step=1.7s, eta=0:12:42\n",
      "2021-05-12 10:00:59 [INFO]\t[TRAIN] Epoch=5/10, Step=66/66, loss=0.024344, lr=0.005373, time_each_step=1.7s, eta=0:12:39\n",
      "2021-05-12 10:00:59 [INFO]\t[TRAIN] Epoch 5 finished, loss=0.015949, lr=0.005845 .\n",
      "2021-05-12 10:00:59 [INFO]\tStart to evaluating(total_samples=76, total_steps=19)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 10:01:16 [INFO]\t[EVAL] Finished, Epoch=5, miou=0.868783, category_iou=[0.99478112 0.74278569], oacc=0.994859, category_acc=[0.99712545 0.86505228], kappa=0.849796, category_F1-score=[0.99738373 0.85241197] .\n",
      "2021-05-12 10:01:16 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/best_model.\n",
      "2021-05-12 10:01:17 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/epoch_5.\n",
      "2021-05-12 10:01:17 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_5, miou=0.8687834076720595\n",
      "2021-05-12 10:01:33 [INFO]\t[TRAIN] Epoch=6/10, Step=2/66, loss=0.020601, lr=0.005344, time_each_step=2.35s, eta=0:12:47\n",
      "2021-05-12 10:01:37 [INFO]\t[TRAIN] Epoch=6/10, Step=4/66, loss=0.011115, lr=0.005315, time_each_step=2.4s, eta=0:12:45\n",
      "2021-05-12 10:01:41 [INFO]\t[TRAIN] Epoch=6/10, Step=6/66, loss=0.008193, lr=0.005286, time_each_step=2.44s, eta=0:12:43\n",
      "2021-05-12 10:01:46 [INFO]\t[TRAIN] Epoch=6/10, Step=8/66, loss=0.017787, lr=0.005256, time_each_step=2.47s, eta=0:12:40\n",
      "2021-05-12 10:01:50 [INFO]\t[TRAIN] Epoch=6/10, Step=10/66, loss=0.011381, lr=0.005227, time_each_step=2.51s, eta=0:12:37\n",
      "2021-05-12 10:01:54 [INFO]\t[TRAIN] Epoch=6/10, Step=12/66, loss=0.015329, lr=0.005198, time_each_step=2.54s, eta=0:12:33\n",
      "2021-05-12 10:01:57 [INFO]\t[TRAIN] Epoch=6/10, Step=14/66, loss=0.014812, lr=0.005168, time_each_step=2.55s, eta=0:12:29\n",
      "2021-05-12 10:02:01 [INFO]\t[TRAIN] Epoch=6/10, Step=16/66, loss=0.022795, lr=0.005139, time_each_step=2.55s, eta=0:12:24\n",
      "2021-05-12 10:02:04 [INFO]\t[TRAIN] Epoch=6/10, Step=18/66, loss=0.011799, lr=0.00511, time_each_step=2.55s, eta=0:12:19\n",
      "2021-05-12 10:02:08 [INFO]\t[TRAIN] Epoch=6/10, Step=20/66, loss=0.009245, lr=0.00508, time_each_step=2.55s, eta=0:12:13\n",
      "2021-05-12 10:02:11 [INFO]\t[TRAIN] Epoch=6/10, Step=22/66, loss=0.020726, lr=0.005051, time_each_step=1.9s, eta=0:11:40\n",
      "2021-05-12 10:02:14 [INFO]\t[TRAIN] Epoch=6/10, Step=24/66, loss=0.010023, lr=0.005022, time_each_step=1.85s, eta=0:11:34\n",
      "2021-05-12 10:02:18 [INFO]\t[TRAIN] Epoch=6/10, Step=26/66, loss=0.01258, lr=0.004992, time_each_step=1.83s, eta=0:11:29\n",
      "2021-05-12 10:02:22 [INFO]\t[TRAIN] Epoch=6/10, Step=28/66, loss=0.016879, lr=0.004963, time_each_step=1.8s, eta=0:11:25\n",
      "2021-05-12 10:02:25 [INFO]\t[TRAIN] Epoch=6/10, Step=30/66, loss=0.016668, lr=0.004933, time_each_step=1.76s, eta=0:11:19\n",
      "2021-05-12 10:02:28 [INFO]\t[TRAIN] Epoch=6/10, Step=32/66, loss=0.015226, lr=0.004904, time_each_step=1.73s, eta=0:11:15\n",
      "2021-05-12 10:02:32 [INFO]\t[TRAIN] Epoch=6/10, Step=34/66, loss=0.009183, lr=0.004874, time_each_step=1.72s, eta=0:11:11\n",
      "2021-05-12 10:02:35 [INFO]\t[TRAIN] Epoch=6/10, Step=36/66, loss=0.007659, lr=0.004845, time_each_step=1.72s, eta=0:11:8\n",
      "2021-05-12 10:02:38 [INFO]\t[TRAIN] Epoch=6/10, Step=38/66, loss=0.013857, lr=0.004815, time_each_step=1.71s, eta=0:11:4\n",
      "2021-05-12 10:02:42 [INFO]\t[TRAIN] Epoch=6/10, Step=40/66, loss=0.009543, lr=0.004785, time_each_step=1.72s, eta=0:11:1\n",
      "2021-05-12 10:02:45 [INFO]\t[TRAIN] Epoch=6/10, Step=42/66, loss=0.013024, lr=0.004756, time_each_step=1.72s, eta=0:10:58\n",
      "2021-05-12 10:02:49 [INFO]\t[TRAIN] Epoch=6/10, Step=44/66, loss=0.008061, lr=0.004726, time_each_step=1.74s, eta=0:10:54\n",
      "2021-05-12 10:02:53 [INFO]\t[TRAIN] Epoch=6/10, Step=46/66, loss=0.009748, lr=0.004696, time_each_step=1.72s, eta=0:10:51\n",
      "2021-05-12 10:02:56 [INFO]\t[TRAIN] Epoch=6/10, Step=48/66, loss=0.011499, lr=0.004667, time_each_step=1.72s, eta=0:10:47\n",
      "2021-05-12 10:02:59 [INFO]\t[TRAIN] Epoch=6/10, Step=50/66, loss=0.009106, lr=0.004637, time_each_step=1.73s, eta=0:10:44\n",
      "2021-05-12 10:03:03 [INFO]\t[TRAIN] Epoch=6/10, Step=52/66, loss=0.018094, lr=0.004607, time_each_step=1.74s, eta=0:10:40\n",
      "2021-05-12 10:03:07 [INFO]\t[TRAIN] Epoch=6/10, Step=54/66, loss=0.011074, lr=0.004578, time_each_step=1.74s, eta=0:10:37\n",
      "2021-05-12 10:03:10 [INFO]\t[TRAIN] Epoch=6/10, Step=56/66, loss=0.014368, lr=0.004548, time_each_step=1.75s, eta=0:10:34\n",
      "2021-05-12 10:03:13 [INFO]\t[TRAIN] Epoch=6/10, Step=58/66, loss=0.012397, lr=0.004518, time_each_step=1.75s, eta=0:10:30\n",
      "2021-05-12 10:03:17 [INFO]\t[TRAIN] Epoch=6/10, Step=60/66, loss=0.009757, lr=0.004488, time_each_step=1.75s, eta=0:10:27\n",
      "2021-05-12 10:03:21 [INFO]\t[TRAIN] Epoch=6/10, Step=62/66, loss=0.013488, lr=0.004458, time_each_step=1.76s, eta=0:10:23\n",
      "2021-05-12 10:03:24 [INFO]\t[TRAIN] Epoch=6/10, Step=64/66, loss=0.009125, lr=0.004429, time_each_step=1.76s, eta=0:10:20\n",
      "2021-05-12 10:03:28 [INFO]\t[TRAIN] Epoch=6/10, Step=66/66, loss=0.021039, lr=0.004399, time_each_step=1.75s, eta=0:10:16\n",
      "2021-05-12 10:03:28 [INFO]\t[TRAIN] Epoch 6 finished, loss=0.014639, lr=0.004881 .\n",
      "2021-05-12 10:03:28 [INFO]\tStart to evaluating(total_samples=76, total_steps=19)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 10:03:45 [INFO]\t[EVAL] Finished, Epoch=6, miou=0.871735, category_iou=[0.99511876 0.74835039], oacc=0.995189, category_acc=[0.99658163 0.9081629 ], kappa=0.853626, category_F1-score=[0.99755341 0.85606455] .\n",
      "2021-05-12 10:03:45 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/best_model.\n",
      "2021-05-12 10:03:46 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/epoch_6.\n",
      "2021-05-12 10:03:46 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_6, miou=0.8717345750235628\n",
      "2021-05-12 10:04:02 [INFO]\t[TRAIN] Epoch=7/10, Step=2/66, loss=0.013008, lr=0.004369, time_each_step=2.41s, eta=0:10:19\n",
      "2021-05-12 10:04:06 [INFO]\t[TRAIN] Epoch=7/10, Step=4/66, loss=0.013818, lr=0.004339, time_each_step=2.43s, eta=0:10:16\n",
      "2021-05-12 10:04:11 [INFO]\t[TRAIN] Epoch=7/10, Step=6/66, loss=0.008361, lr=0.004309, time_each_step=2.47s, eta=0:10:13\n",
      "2021-05-12 10:04:15 [INFO]\t[TRAIN] Epoch=7/10, Step=8/66, loss=0.016674, lr=0.004279, time_each_step=2.5s, eta=0:10:10\n",
      "2021-05-12 10:04:19 [INFO]\t[TRAIN] Epoch=7/10, Step=10/66, loss=0.008361, lr=0.004249, time_each_step=2.54s, eta=0:10:7\n",
      "2021-05-12 10:04:23 [INFO]\t[TRAIN] Epoch=7/10, Step=12/66, loss=0.010601, lr=0.004219, time_each_step=2.56s, eta=0:10:3\n",
      "2021-05-12 10:04:26 [INFO]\t[TRAIN] Epoch=7/10, Step=14/66, loss=0.023391, lr=0.004189, time_each_step=2.56s, eta=0:9:58\n",
      "2021-05-12 10:04:30 [INFO]\t[TRAIN] Epoch=7/10, Step=16/66, loss=0.008695, lr=0.004159, time_each_step=2.54s, eta=0:9:52\n",
      "2021-05-12 10:04:33 [INFO]\t[TRAIN] Epoch=7/10, Step=18/66, loss=0.012076, lr=0.004129, time_each_step=2.54s, eta=0:9:46\n",
      "2021-05-12 10:04:37 [INFO]\t[TRAIN] Epoch=7/10, Step=20/66, loss=0.010807, lr=0.004099, time_each_step=2.55s, eta=0:9:42\n",
      "2021-05-12 10:04:40 [INFO]\t[TRAIN] Epoch=7/10, Step=22/66, loss=0.013199, lr=0.004069, time_each_step=1.89s, eta=0:9:8\n",
      "2021-05-12 10:04:43 [INFO]\t[TRAIN] Epoch=7/10, Step=24/66, loss=0.010532, lr=0.004039, time_each_step=1.85s, eta=0:9:2\n",
      "2021-05-12 10:04:47 [INFO]\t[TRAIN] Epoch=7/10, Step=26/66, loss=0.015303, lr=0.004008, time_each_step=1.8s, eta=0:8:57\n",
      "2021-05-12 10:04:50 [INFO]\t[TRAIN] Epoch=7/10, Step=28/66, loss=0.019177, lr=0.003978, time_each_step=1.77s, eta=0:8:52\n",
      "2021-05-12 10:04:54 [INFO]\t[TRAIN] Epoch=7/10, Step=30/66, loss=0.022096, lr=0.003948, time_each_step=1.73s, eta=0:8:47\n",
      "2021-05-12 10:04:57 [INFO]\t[TRAIN] Epoch=7/10, Step=32/66, loss=0.044294, lr=0.003918, time_each_step=1.71s, eta=0:8:43\n",
      "2021-05-12 10:05:00 [INFO]\t[TRAIN] Epoch=7/10, Step=34/66, loss=0.009283, lr=0.003887, time_each_step=1.71s, eta=0:8:39\n",
      "2021-05-12 10:05:04 [INFO]\t[TRAIN] Epoch=7/10, Step=36/66, loss=0.017852, lr=0.003857, time_each_step=1.71s, eta=0:8:36\n",
      "2021-05-12 10:05:07 [INFO]\t[TRAIN] Epoch=7/10, Step=38/66, loss=0.021457, lr=0.003827, time_each_step=1.71s, eta=0:8:32\n",
      "2021-05-12 10:05:11 [INFO]\t[TRAIN] Epoch=7/10, Step=40/66, loss=0.008389, lr=0.003796, time_each_step=1.71s, eta=0:8:29\n",
      "2021-05-12 10:05:14 [INFO]\t[TRAIN] Epoch=7/10, Step=42/66, loss=0.010173, lr=0.003766, time_each_step=1.71s, eta=0:8:26\n",
      "2021-05-12 10:05:18 [INFO]\t[TRAIN] Epoch=7/10, Step=44/66, loss=0.01221, lr=0.003736, time_each_step=1.72s, eta=0:8:22\n",
      "2021-05-12 10:05:21 [INFO]\t[TRAIN] Epoch=7/10, Step=46/66, loss=0.018023, lr=0.003705, time_each_step=1.73s, eta=0:8:19\n",
      "2021-05-12 10:05:25 [INFO]\t[TRAIN] Epoch=7/10, Step=48/66, loss=0.016879, lr=0.003675, time_each_step=1.73s, eta=0:8:16\n",
      "2021-05-12 10:05:28 [INFO]\t[TRAIN] Epoch=7/10, Step=50/66, loss=0.015167, lr=0.003644, time_each_step=1.74s, eta=0:8:12\n",
      "2021-05-12 10:05:32 [INFO]\t[TRAIN] Epoch=7/10, Step=52/66, loss=0.011148, lr=0.003614, time_each_step=1.74s, eta=0:8:9\n",
      "2021-05-12 10:05:35 [INFO]\t[TRAIN] Epoch=7/10, Step=54/66, loss=0.018848, lr=0.003583, time_each_step=1.74s, eta=0:8:6\n",
      "2021-05-12 10:05:39 [INFO]\t[TRAIN] Epoch=7/10, Step=56/66, loss=0.011332, lr=0.003553, time_each_step=1.75s, eta=0:8:2\n",
      "2021-05-12 10:05:42 [INFO]\t[TRAIN] Epoch=7/10, Step=58/66, loss=0.014843, lr=0.003522, time_each_step=1.75s, eta=0:7:59\n",
      "2021-05-12 10:05:45 [INFO]\t[TRAIN] Epoch=7/10, Step=60/66, loss=0.015916, lr=0.003491, time_each_step=1.73s, eta=0:7:55\n",
      "2021-05-12 10:05:49 [INFO]\t[TRAIN] Epoch=7/10, Step=62/66, loss=0.018266, lr=0.003461, time_each_step=1.74s, eta=0:7:52\n",
      "2021-05-12 10:05:52 [INFO]\t[TRAIN] Epoch=7/10, Step=64/66, loss=0.01108, lr=0.00343, time_each_step=1.73s, eta=0:7:48\n",
      "2021-05-12 10:05:55 [INFO]\t[TRAIN] Epoch=7/10, Step=66/66, loss=0.015931, lr=0.003399, time_each_step=1.72s, eta=0:7:45\n",
      "2021-05-12 10:05:55 [INFO]\t[TRAIN] Epoch 7 finished, loss=0.01447, lr=0.003894 .\n",
      "2021-05-12 10:05:55 [INFO]\tStart to evaluating(total_samples=76, total_steps=19)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:16<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 10:06:12 [INFO]\t[EVAL] Finished, Epoch=7, miou=0.87312, category_iou=[0.99503831 0.7512016 ], oacc=0.995112, category_acc=[0.99703766 0.88194625], kappa=0.855442, category_F1-score=[0.99751299 0.85792704] .\n",
      "2021-05-12 10:06:12 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/best_model.\n",
      "2021-05-12 10:06:13 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/epoch_7.\n",
      "2021-05-12 10:06:13 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_7, miou=0.8731199585019\n",
      "2021-05-12 10:06:28 [INFO]\t[TRAIN] Epoch=8/10, Step=2/66, loss=0.023618, lr=0.003368, time_each_step=2.33s, eta=0:7:40\n",
      "2021-05-12 10:06:34 [INFO]\t[TRAIN] Epoch=8/10, Step=4/66, loss=0.018029, lr=0.003338, time_each_step=2.42s, eta=0:7:41\n",
      "2021-05-12 10:06:38 [INFO]\t[TRAIN] Epoch=8/10, Step=6/66, loss=0.015062, lr=0.003307, time_each_step=2.46s, eta=0:7:38\n",
      "2021-05-12 10:06:42 [INFO]\t[TRAIN] Epoch=8/10, Step=8/66, loss=0.007999, lr=0.003276, time_each_step=2.49s, eta=0:7:35\n",
      "2021-05-12 10:06:46 [INFO]\t[TRAIN] Epoch=8/10, Step=10/66, loss=0.008001, lr=0.003245, time_each_step=2.53s, eta=0:7:32\n",
      "2021-05-12 10:06:50 [INFO]\t[TRAIN] Epoch=8/10, Step=12/66, loss=0.01289, lr=0.003214, time_each_step=2.54s, eta=0:7:28\n",
      "2021-05-12 10:06:54 [INFO]\t[TRAIN] Epoch=8/10, Step=14/66, loss=0.010636, lr=0.003183, time_each_step=2.55s, eta=0:7:23\n",
      "2021-05-12 10:06:57 [INFO]\t[TRAIN] Epoch=8/10, Step=16/66, loss=0.012431, lr=0.003152, time_each_step=2.55s, eta=0:7:18\n",
      "2021-05-12 10:07:00 [INFO]\t[TRAIN] Epoch=8/10, Step=18/66, loss=0.013043, lr=0.003121, time_each_step=2.55s, eta=0:7:13\n",
      "2021-05-12 10:07:04 [INFO]\t[TRAIN] Epoch=8/10, Step=20/66, loss=0.011082, lr=0.00309, time_each_step=2.56s, eta=0:7:8\n",
      "2021-05-12 10:07:07 [INFO]\t[TRAIN] Epoch=8/10, Step=22/66, loss=0.015732, lr=0.003059, time_each_step=1.95s, eta=0:6:37\n",
      "2021-05-12 10:07:11 [INFO]\t[TRAIN] Epoch=8/10, Step=24/66, loss=0.021308, lr=0.003028, time_each_step=1.84s, eta=0:6:28\n",
      "2021-05-12 10:07:14 [INFO]\t[TRAIN] Epoch=8/10, Step=26/66, loss=0.01164, lr=0.002997, time_each_step=1.81s, eta=0:6:23\n",
      "2021-05-12 10:07:18 [INFO]\t[TRAIN] Epoch=8/10, Step=28/66, loss=0.012969, lr=0.002966, time_each_step=1.79s, eta=0:6:19\n",
      "2021-05-12 10:07:21 [INFO]\t[TRAIN] Epoch=8/10, Step=30/66, loss=0.01312, lr=0.002934, time_each_step=1.73s, eta=0:6:13\n",
      "2021-05-12 10:07:25 [INFO]\t[TRAIN] Epoch=8/10, Step=32/66, loss=0.009164, lr=0.002903, time_each_step=1.72s, eta=0:6:9\n",
      "2021-05-12 10:07:28 [INFO]\t[TRAIN] Epoch=8/10, Step=34/66, loss=0.011937, lr=0.002872, time_each_step=1.72s, eta=0:6:6\n",
      "2021-05-12 10:07:31 [INFO]\t[TRAIN] Epoch=8/10, Step=36/66, loss=0.011914, lr=0.00284, time_each_step=1.72s, eta=0:6:2\n",
      "2021-05-12 10:07:35 [INFO]\t[TRAIN] Epoch=8/10, Step=38/66, loss=0.008295, lr=0.002809, time_each_step=1.73s, eta=0:5:59\n",
      "2021-05-12 10:07:39 [INFO]\t[TRAIN] Epoch=8/10, Step=40/66, loss=0.013204, lr=0.002778, time_each_step=1.74s, eta=0:5:56\n",
      "2021-05-12 10:07:42 [INFO]\t[TRAIN] Epoch=8/10, Step=42/66, loss=0.009803, lr=0.002746, time_each_step=1.73s, eta=0:5:52\n",
      "2021-05-12 10:07:45 [INFO]\t[TRAIN] Epoch=8/10, Step=44/66, loss=0.010415, lr=0.002715, time_each_step=1.72s, eta=0:5:49\n",
      "2021-05-12 10:07:49 [INFO]\t[TRAIN] Epoch=8/10, Step=46/66, loss=0.00962, lr=0.002683, time_each_step=1.72s, eta=0:5:45\n",
      "2021-05-12 10:07:52 [INFO]\t[TRAIN] Epoch=8/10, Step=48/66, loss=0.008859, lr=0.002651, time_each_step=1.71s, eta=0:5:42\n",
      "2021-05-12 10:07:55 [INFO]\t[TRAIN] Epoch=8/10, Step=50/66, loss=0.01043, lr=0.00262, time_each_step=1.71s, eta=0:5:38\n",
      "2021-05-12 10:07:59 [INFO]\t[TRAIN] Epoch=8/10, Step=52/66, loss=0.00704, lr=0.002588, time_each_step=1.71s, eta=0:5:35\n",
      "2021-05-12 10:08:02 [INFO]\t[TRAIN] Epoch=8/10, Step=54/66, loss=0.015266, lr=0.002556, time_each_step=1.71s, eta=0:5:31\n",
      "2021-05-12 10:08:06 [INFO]\t[TRAIN] Epoch=8/10, Step=56/66, loss=0.008702, lr=0.002525, time_each_step=1.71s, eta=0:5:28\n",
      "2021-05-12 10:08:09 [INFO]\t[TRAIN] Epoch=8/10, Step=58/66, loss=0.010072, lr=0.002493, time_each_step=1.7s, eta=0:5:24\n",
      "2021-05-12 10:08:12 [INFO]\t[TRAIN] Epoch=8/10, Step=60/66, loss=0.007374, lr=0.002461, time_each_step=1.69s, eta=0:5:21\n",
      "2021-05-12 10:08:16 [INFO]\t[TRAIN] Epoch=8/10, Step=62/66, loss=0.010763, lr=0.002429, time_each_step=1.7s, eta=0:5:18\n",
      "2021-05-12 10:08:19 [INFO]\t[TRAIN] Epoch=8/10, Step=64/66, loss=0.022336, lr=0.002397, time_each_step=1.71s, eta=0:5:14\n",
      "2021-05-12 10:08:23 [INFO]\t[TRAIN] Epoch=8/10, Step=66/66, loss=0.016699, lr=0.002365, time_each_step=1.71s, eta=0:5:11\n",
      "2021-05-12 10:08:23 [INFO]\t[TRAIN] Epoch 8 finished, loss=0.014119, lr=0.002878 .\n",
      "2021-05-12 10:08:23 [INFO]\tStart to evaluating(total_samples=76, total_steps=19)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 10:08:40 [INFO]\t[EVAL] Finished, Epoch=8, miou=0.873558, category_iou=[0.99514999 0.75196696], oacc=0.99522, category_acc=[0.99676623 0.90067703], kappa=0.856, category_F1-score=[0.9975691  0.85842596] .\n",
      "2021-05-12 10:08:40 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/best_model.\n",
      "2021-05-12 10:08:40 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/epoch_8.\n",
      "2021-05-12 10:08:40 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_8, miou=0.8735584732839974\n",
      "2021-05-12 10:08:56 [INFO]\t[TRAIN] Epoch=9/10, Step=2/66, loss=0.014727, lr=0.002333, time_each_step=2.34s, eta=0:5:14\n",
      "2021-05-12 10:09:01 [INFO]\t[TRAIN] Epoch=9/10, Step=4/66, loss=0.014705, lr=0.002301, time_each_step=2.38s, eta=0:5:12\n",
      "2021-05-12 10:09:05 [INFO]\t[TRAIN] Epoch=9/10, Step=6/66, loss=0.009245, lr=0.002269, time_each_step=2.42s, eta=0:5:10\n",
      "2021-05-12 10:09:09 [INFO]\t[TRAIN] Epoch=9/10, Step=8/66, loss=0.013425, lr=0.002237, time_each_step=2.45s, eta=0:5:7\n",
      "2021-05-12 10:09:13 [INFO]\t[TRAIN] Epoch=9/10, Step=10/66, loss=0.007956, lr=0.002205, time_each_step=2.5s, eta=0:5:5\n",
      "2021-05-12 10:09:17 [INFO]\t[TRAIN] Epoch=9/10, Step=12/66, loss=0.0117, lr=0.002172, time_each_step=2.51s, eta=0:5:0\n",
      "2021-05-12 10:09:20 [INFO]\t[TRAIN] Epoch=9/10, Step=14/66, loss=0.0129, lr=0.00214, time_each_step=2.51s, eta=0:4:55\n",
      "2021-05-12 10:09:24 [INFO]\t[TRAIN] Epoch=9/10, Step=16/66, loss=0.01298, lr=0.002108, time_each_step=2.51s, eta=0:4:50\n",
      "2021-05-12 10:09:27 [INFO]\t[TRAIN] Epoch=9/10, Step=18/66, loss=0.017424, lr=0.002075, time_each_step=2.5s, eta=0:4:45\n",
      "2021-05-12 10:09:30 [INFO]\t[TRAIN] Epoch=9/10, Step=20/66, loss=0.044525, lr=0.002043, time_each_step=2.5s, eta=0:4:40\n",
      "2021-05-12 10:09:34 [INFO]\t[TRAIN] Epoch=9/10, Step=22/66, loss=0.010866, lr=0.00201, time_each_step=1.88s, eta=0:4:7\n",
      "2021-05-12 10:09:37 [INFO]\t[TRAIN] Epoch=9/10, Step=24/66, loss=0.00995, lr=0.001977, time_each_step=1.84s, eta=0:4:2\n",
      "2021-05-12 10:09:41 [INFO]\t[TRAIN] Epoch=9/10, Step=26/66, loss=0.01057, lr=0.001945, time_each_step=1.81s, eta=0:3:57\n",
      "2021-05-12 10:09:45 [INFO]\t[TRAIN] Epoch=9/10, Step=28/66, loss=0.010632, lr=0.001912, time_each_step=1.79s, eta=0:3:53\n",
      "2021-05-12 10:09:48 [INFO]\t[TRAIN] Epoch=9/10, Step=30/66, loss=0.016599, lr=0.001879, time_each_step=1.76s, eta=0:3:48\n",
      "2021-05-12 10:09:52 [INFO]\t[TRAIN] Epoch=9/10, Step=32/66, loss=0.013806, lr=0.001846, time_each_step=1.75s, eta=0:3:44\n",
      "2021-05-12 10:09:55 [INFO]\t[TRAIN] Epoch=9/10, Step=34/66, loss=0.010912, lr=0.001813, time_each_step=1.76s, eta=0:3:41\n",
      "2021-05-12 10:09:59 [INFO]\t[TRAIN] Epoch=9/10, Step=36/66, loss=0.010664, lr=0.00178, time_each_step=1.76s, eta=0:3:37\n",
      "2021-05-12 10:10:02 [INFO]\t[TRAIN] Epoch=9/10, Step=38/66, loss=0.019924, lr=0.001747, time_each_step=1.77s, eta=0:3:34\n",
      "2021-05-12 10:10:06 [INFO]\t[TRAIN] Epoch=9/10, Step=40/66, loss=0.009227, lr=0.001714, time_each_step=1.76s, eta=0:3:31\n",
      "2021-05-12 10:10:09 [INFO]\t[TRAIN] Epoch=9/10, Step=42/66, loss=0.013289, lr=0.001681, time_each_step=1.77s, eta=0:3:27\n",
      "2021-05-12 10:10:13 [INFO]\t[TRAIN] Epoch=9/10, Step=44/66, loss=0.008525, lr=0.001648, time_each_step=1.77s, eta=0:3:24\n",
      "2021-05-12 10:10:16 [INFO]\t[TRAIN] Epoch=9/10, Step=46/66, loss=0.009397, lr=0.001614, time_each_step=1.76s, eta=0:3:20\n",
      "2021-05-12 10:10:19 [INFO]\t[TRAIN] Epoch=9/10, Step=48/66, loss=0.019577, lr=0.001581, time_each_step=1.74s, eta=0:3:16\n",
      "2021-05-12 10:10:23 [INFO]\t[TRAIN] Epoch=9/10, Step=50/66, loss=0.018505, lr=0.001547, time_each_step=1.72s, eta=0:3:12\n",
      "2021-05-12 10:10:26 [INFO]\t[TRAIN] Epoch=9/10, Step=52/66, loss=0.010959, lr=0.001514, time_each_step=1.72s, eta=0:3:9\n",
      "2021-05-12 10:10:29 [INFO]\t[TRAIN] Epoch=9/10, Step=54/66, loss=0.008057, lr=0.00148, time_each_step=1.71s, eta=0:3:5\n",
      "2021-05-12 10:10:33 [INFO]\t[TRAIN] Epoch=9/10, Step=56/66, loss=0.008684, lr=0.001446, time_each_step=1.7s, eta=0:3:2\n",
      "2021-05-12 10:10:36 [INFO]\t[TRAIN] Epoch=9/10, Step=58/66, loss=0.008681, lr=0.001412, time_each_step=1.7s, eta=0:2:58\n",
      "2021-05-12 10:10:40 [INFO]\t[TRAIN] Epoch=9/10, Step=60/66, loss=0.01313, lr=0.001378, time_each_step=1.7s, eta=0:2:55\n",
      "2021-05-12 10:10:43 [INFO]\t[TRAIN] Epoch=9/10, Step=62/66, loss=0.016589, lr=0.001344, time_each_step=1.69s, eta=0:2:51\n",
      "2021-05-12 10:10:47 [INFO]\t[TRAIN] Epoch=9/10, Step=64/66, loss=0.010541, lr=0.00131, time_each_step=1.71s, eta=0:2:48\n",
      "2021-05-12 10:10:50 [INFO]\t[TRAIN] Epoch=9/10, Step=66/66, loss=0.031358, lr=0.001276, time_each_step=1.72s, eta=0:2:45\n",
      "2021-05-12 10:10:50 [INFO]\t[TRAIN] Epoch 9 finished, loss=0.014268, lr=0.001819 .\n",
      "2021-05-12 10:10:50 [INFO]\tStart to evaluating(total_samples=76, total_steps=19)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:16<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 10:11:07 [INFO]\t[EVAL] Finished, Epoch=9, miou=0.878042, category_iou=[0.99528654 0.76079835], oacc=0.995356, category_acc=[0.9970488  0.89453528], kappa=0.861792, category_F1-score=[0.9976377  0.86415159] .\n",
      "2021-05-12 10:11:07 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/best_model.\n",
      "2021-05-12 10:11:08 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/epoch_9.\n",
      "2021-05-12 10:11:08 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_9, miou=0.878042443418493\n",
      "2021-05-12 10:11:24 [INFO]\t[TRAIN] Epoch=10/10, Step=2/66, loss=0.013437, lr=0.001242, time_each_step=2.35s, eta=0:2:48\n",
      "2021-05-12 10:11:29 [INFO]\t[TRAIN] Epoch=10/10, Step=4/66, loss=0.011733, lr=0.001207, time_each_step=2.39s, eta=0:2:46\n",
      "2021-05-12 10:11:33 [INFO]\t[TRAIN] Epoch=10/10, Step=6/66, loss=0.011967, lr=0.001173, time_each_step=2.42s, eta=0:2:43\n",
      "2021-05-12 10:11:37 [INFO]\t[TRAIN] Epoch=10/10, Step=8/66, loss=0.018182, lr=0.001138, time_each_step=2.46s, eta=0:2:40\n",
      "2021-05-12 10:11:41 [INFO]\t[TRAIN] Epoch=10/10, Step=10/66, loss=0.010505, lr=0.001103, time_each_step=2.51s, eta=0:2:38\n",
      "2021-05-12 10:11:45 [INFO]\t[TRAIN] Epoch=10/10, Step=12/66, loss=0.010711, lr=0.001068, time_each_step=2.53s, eta=0:2:34\n",
      "2021-05-12 10:11:48 [INFO]\t[TRAIN] Epoch=10/10, Step=14/66, loss=0.025283, lr=0.001033, time_each_step=2.54s, eta=0:2:29\n",
      "2021-05-12 10:11:52 [INFO]\t[TRAIN] Epoch=10/10, Step=16/66, loss=0.01719, lr=0.000998, time_each_step=2.55s, eta=0:2:25\n",
      "2021-05-12 10:11:56 [INFO]\t[TRAIN] Epoch=10/10, Step=18/66, loss=0.016952, lr=0.000963, time_each_step=2.53s, eta=0:2:19\n",
      "2021-05-12 10:11:59 [INFO]\t[TRAIN] Epoch=10/10, Step=20/66, loss=0.012393, lr=0.000927, time_each_step=2.52s, eta=0:2:14\n",
      "2021-05-12 10:12:02 [INFO]\t[TRAIN] Epoch=10/10, Step=22/66, loss=0.008678, lr=0.000892, time_each_step=1.89s, eta=0:1:41\n",
      "2021-05-12 10:12:06 [INFO]\t[TRAIN] Epoch=10/10, Step=24/66, loss=0.015186, lr=0.000856, time_each_step=1.85s, eta=0:1:35\n",
      "2021-05-12 10:12:09 [INFO]\t[TRAIN] Epoch=10/10, Step=26/66, loss=0.020754, lr=0.00082, time_each_step=1.82s, eta=0:1:30\n",
      "2021-05-12 10:12:12 [INFO]\t[TRAIN] Epoch=10/10, Step=28/66, loss=0.014779, lr=0.000784, time_each_step=1.79s, eta=0:1:25\n",
      "2021-05-12 10:12:16 [INFO]\t[TRAIN] Epoch=10/10, Step=30/66, loss=0.009313, lr=0.000748, time_each_step=1.73s, eta=0:1:20\n",
      "2021-05-12 10:12:19 [INFO]\t[TRAIN] Epoch=10/10, Step=32/66, loss=0.012937, lr=0.000711, time_each_step=1.71s, eta=0:1:16\n",
      "2021-05-12 10:12:22 [INFO]\t[TRAIN] Epoch=10/10, Step=34/66, loss=0.012567, lr=0.000675, time_each_step=1.7s, eta=0:1:12\n",
      "2021-05-12 10:12:26 [INFO]\t[TRAIN] Epoch=10/10, Step=36/66, loss=0.007955, lr=0.000638, time_each_step=1.68s, eta=0:1:8\n",
      "2021-05-12 10:12:29 [INFO]\t[TRAIN] Epoch=10/10, Step=38/66, loss=0.012585, lr=0.000601, time_each_step=1.67s, eta=0:1:4\n",
      "2021-05-12 10:12:32 [INFO]\t[TRAIN] Epoch=10/10, Step=40/66, loss=0.007789, lr=0.000563, time_each_step=1.67s, eta=0:1:1\n",
      "2021-05-12 10:12:36 [INFO]\t[TRAIN] Epoch=10/10, Step=42/66, loss=0.014755, lr=0.000525, time_each_step=1.66s, eta=0:0:57\n",
      "2021-05-12 10:12:39 [INFO]\t[TRAIN] Epoch=10/10, Step=44/66, loss=0.009324, lr=0.000487, time_each_step=1.66s, eta=0:0:54\n",
      "2021-05-12 10:12:42 [INFO]\t[TRAIN] Epoch=10/10, Step=46/66, loss=0.009586, lr=0.000449, time_each_step=1.66s, eta=0:0:51\n",
      "2021-05-12 10:12:45 [INFO]\t[TRAIN] Epoch=10/10, Step=48/66, loss=0.011581, lr=0.00041, time_each_step=1.66s, eta=0:0:47\n",
      "2021-05-12 10:12:49 [INFO]\t[TRAIN] Epoch=10/10, Step=50/66, loss=0.011783, lr=0.000371, time_each_step=1.66s, eta=0:0:44\n",
      "2021-05-12 10:12:52 [INFO]\t[TRAIN] Epoch=10/10, Step=52/66, loss=0.011744, lr=0.000332, time_each_step=1.66s, eta=0:0:41\n",
      "2021-05-12 10:12:56 [INFO]\t[TRAIN] Epoch=10/10, Step=54/66, loss=0.010553, lr=0.000292, time_each_step=1.68s, eta=0:0:38\n",
      "2021-05-12 10:12:59 [INFO]\t[TRAIN] Epoch=10/10, Step=56/66, loss=0.02672, lr=0.000251, time_each_step=1.68s, eta=0:0:34\n",
      "2021-05-12 10:13:03 [INFO]\t[TRAIN] Epoch=10/10, Step=58/66, loss=0.009555, lr=0.00021, time_each_step=1.69s, eta=0:0:31\n",
      "2021-05-12 10:13:06 [INFO]\t[TRAIN] Epoch=10/10, Step=60/66, loss=0.010033, lr=0.000167, time_each_step=1.69s, eta=0:0:28\n",
      "2021-05-12 10:13:09 [INFO]\t[TRAIN] Epoch=10/10, Step=62/66, loss=0.011402, lr=0.000123, time_each_step=1.69s, eta=0:0:24\n",
      "2021-05-12 10:13:13 [INFO]\t[TRAIN] Epoch=10/10, Step=64/66, loss=0.025886, lr=7.8e-05, time_each_step=1.69s, eta=0:0:21\n",
      "2021-05-12 10:13:16 [INFO]\t[TRAIN] Epoch=10/10, Step=66/66, loss=0.010877, lr=2.9e-05, time_each_step=1.69s, eta=0:0:18\n",
      "2021-05-12 10:13:16 [INFO]\t[TRAIN] Epoch 10 finished, loss=0.013597, lr=0.000672 .\n",
      "2021-05-12 10:13:16 [INFO]\tStart to evaluating(total_samples=76, total_steps=19)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:16<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 10:13:33 [INFO]\t[EVAL] Finished, Epoch=10, miou=0.877277, category_iou=[0.99527721 0.75927725], oacc=0.995347, category_acc=[0.99695548 0.89846722], kappa=0.860806, category_F1-score=[0.99763301 0.86316952] .\n",
      "2021-05-12 10:13:33 [INFO]\tModel saved in output/deeplabv3p_mobilenetv3_large_ssld/epoch_10.\n",
      "2021-05-12 10:13:33 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_9, miou=0.878042443418493\n"
     ]
    }
   ],
   "source": [
    "import paddlex as pdx\n",
    "from paddlex.seg import transforms\n",
    "# 定义训练和验证时的transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), transforms.ResizeRangeScaling(),\n",
    "    transforms.RandomPaddingCrop(crop_size=512), transforms.Normalize()\n",
    "])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.ResizeByLong(long_size=512),\n",
    "    transforms.Padding(target_size=512), transforms.Normalize()\n",
    "])\n",
    "\n",
    "# 定义训练和验证所用的数据集\n",
    "\n",
    "train_dataset = pdx.datasets.SegDataset(\n",
    "    data_dir='optic_disc_seg',\n",
    "    file_list='optic_disc_seg/train_list.txt',\n",
    "    label_list='optic_disc_seg/labels.txt',\n",
    "    transforms=train_transforms,\n",
    "    shuffle=True)\n",
    "\n",
    "eval_dataset = pdx.datasets.SegDataset(\n",
    "    data_dir='optic_disc_seg',\n",
    "    file_list='optic_disc_seg/val_list.txt',\n",
    "    label_list='optic_disc_seg/labels.txt',\n",
    "    transforms=eval_transforms)\n",
    "\n",
    "# 初始化模型，并进行训练\n",
    "\n",
    "num_classes = len(train_dataset.labels)\n",
    "\n",
    "model = pdx.seg.DeepLabv3p(\n",
    "    num_classes=num_classes,\n",
    "    backbone='MobileNetV3_large_x1_0_ssld',\n",
    "    pooling_crop_size=(512, 512))\n",
    "\n",
    "\n",
    "model.train(\n",
    "    num_epochs=10,\n",
    "    train_dataset=train_dataset,\n",
    "    train_batch_size=4,\n",
    "    eval_dataset=eval_dataset,\n",
    "    learning_rate=0.01,\n",
    "    save_dir='output/deeplabv3p_mobilenetv3_large_ssld',\n",
    "    use_vdl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.4 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/mobilenet_v3.py:231\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/segmentation/deeplabv3p.py:287\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/segmentation/deeplabv3p.py:315\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-12 10:13:34 [INFO]\tModel[DeepLabv3p] loaded.\n",
      "2021-05-12 10:13:34 [INFO]\tThe visualized result is saved as ./visualize_P0099.jpg\n"
     ]
    }
   ],
   "source": [
    "#从测试数据中随机挑选一张图\n",
    "test_jpg = 'optic_disc_seg/JPEGImages/P0099.jpg'\n",
    "#下载训练好的模型\n",
    "model = pdx.load_model('output/deeplabv3p_mobilenetv3_large_ssld/epoch_10')\n",
    "result = model.predict(test_jpg)\n",
    "pdx.seg.visualize(test_jpg, result, weight=0.0, save_dir='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.5 模型导出\n",
    "导出模型保存在`./inference_model路径下`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/mobilenet_v3.py:231\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/segmentation/deeplabv3p.py:287\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/segmentation/deeplabv3p.py:315\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "2021-05-12 10:13:36 [INFO]\tModel[DeepLabv3p] loaded.\n",
      "2021-05-12 10:13:37 [INFO]\tModel for inference deploy saved in ./inference_model.\n"
     ]
    }
   ],
   "source": [
    "!paddlex --export_inference --model_dir='output/deeplabv3p_mobilenetv3_large_ssld/epoch_10' --save_dir='./inference_model'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
